{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import octomap\n",
    "import datetime\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import RadarPointCloud, LidarPointCloud\n",
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "\n",
    "from ransac_solver import RANSACSolver\n",
    "from radar_pointcloud import *\n",
    "from IPython.display import display\n",
    "import os.path as osp\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_z_one_pose(pose):\n",
    "    output_pose = np.zeros((6,))\n",
    "    state_vector = TransformMatrix4dToVector6d(pose)\n",
    "    output_pose[:2] = state_vector[:2]\n",
    "    output_pose[5] = state_vector[5]\n",
    "    return TransformVector6dToMatrix4d(output_pose)\n",
    "\n",
    "def clear_z(input_pose):\n",
    "    output_poses = np.zeros((input_pose.shape[0], 4, 4))\n",
    "    for i, pose in enumerate(input_pose):\n",
    "        output_poses[i, :, :] = clear_z_one_pose(pose)\n",
    "    return output_poses\n",
    "\n",
    "def TransformMatrix4dToVector6d(H):\n",
    "    x, y, z = H[0, 3], H[1, 3], H[2, 3]\n",
    "\n",
    "    roll = np.arctan2(H[2, 1], H[2, 2])\n",
    "    pitch = np.arctan2(-H[2, 0], np.sqrt(H[0, 0] * H[0, 0] + H[1, 0] * H[1, 0]))\n",
    "    yaw = np.arctan2(H[1, 0], H[0, 0])\n",
    "\n",
    "    v = np.array([x, y, z, roll, pitch, yaw], dtype=np.float64)\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "def TransformVector6dToMatrix4d(v):\n",
    "    x, y, z, roll, pitch, yaw = v[0], v[1], v[2], v[3], v[4], v[5]\n",
    "\n",
    "    cos_roll = np.cos(roll)\n",
    "    sin_roll = np.sin(roll)\n",
    "    cos_pitch = np.cos(pitch)\n",
    "    sin_pitch = np.sin(pitch)\n",
    "    cos_yaw = np.cos(yaw)\n",
    "    sin_yaw = np.sin(yaw)\n",
    "\n",
    "    # Construct the rotation matrix using Rodrigues' rotation formula.\n",
    "    R_yaw = np.array([[cos_yaw, -sin_yaw, 0],\n",
    "                      [sin_yaw, cos_yaw, 0],\n",
    "                      [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "    R_pitch = np.array([[cos_pitch, 0, sin_pitch],\n",
    "                        [0, 1, 0],\n",
    "                        [-sin_pitch, 0, cos_pitch]], dtype=np.float64)\n",
    "\n",
    "    R_roll = np.array([[1, 0, 0],\n",
    "                       [0, cos_roll, -sin_roll],\n",
    "                       [0, sin_roll, cos_roll]], dtype=np.float64)\n",
    "\n",
    "    R = np.dot(np.dot(R_yaw, R_pitch), R_roll)\n",
    "\n",
    "    # Translation vector.\n",
    "    T = np.array([x, y, z], dtype=np.float64)\n",
    "\n",
    "    # Combine the rotation and translation to form the homogeneous matrix.\n",
    "    T_matrix = np.eye(4)\n",
    "    T_matrix[:3, :3] = R\n",
    "    T_matrix[:3, 3] = T\n",
    "\n",
    "    return T_matrix\n",
    "\n",
    "def transform_points(transform, dpoints):\n",
    "    # N x [x y z rcs v v_comp]\n",
    "    result_dpoints = np.zeros_like(dpoints)\n",
    "\n",
    "    points_h = np.ones((dpoints.shape[0], 4))\n",
    "    points_h[:, :3] = dpoints[:, :3]\n",
    "    points_h = (points_h @ transform.T)\n",
    "    result_dpoints[:, :3] = points_h[:, :3]\n",
    "\n",
    "    return result_dpoints\n",
    "\n",
    "\n",
    "def transform_doppler_points(transform, dpoints):\n",
    "    # N x [x y z rcs v v_comp]\n",
    "    result_dpoints = np.zeros_like(dpoints)\n",
    "\n",
    "    points_h = np.ones((dpoints.shape[0], 4))\n",
    "    points_h[:, :3] = dpoints[:, :3]\n",
    "    points_h = (points_h @ transform.T)\n",
    "    result_dpoints[:, :3] = points_h[:, :3]\n",
    "\n",
    "    if dpoints.shape[1] > 3:\n",
    "        result_dpoints[:, 3:] = dpoints[:, 3:]\n",
    "\n",
    "    return result_dpoints\n",
    "\n",
    "\n",
    "def polar_to_cartesian(coordinates):\n",
    "    # Convert degrees to radians\n",
    "    azimuth = coordinates[:, 1]\n",
    "    elevation = np.pi/2 - coordinates[:, 2]\n",
    "\n",
    "    # Calculate Cartesian coordinates\n",
    "    x = coordinates[:, 0] * np.sin(elevation) * np.cos(azimuth)\n",
    "    y = coordinates[:, 0] * np.sin(elevation) * np.sin(azimuth)\n",
    "    z = coordinates[:, 0] * np.cos(elevation)\n",
    "\n",
    "    cartesian_coordinates = np.column_stack((x, y, z))\n",
    "    return cartesian_coordinates\n",
    "\n",
    "\n",
    "def transform_points_to_car_frame(points, calibs):\n",
    "    transformed_points = []\n",
    "    for i in range(points.shape[0]):\n",
    "        point = points[i, :]\n",
    "        sensor_idx = int(point[6])\n",
    "        result_point = np.copy(point)\n",
    "        point_homogeneous = np.ones(4)\n",
    "        point_homogeneous[:3] = point[:3]\n",
    "        T = calibs[sensor_idx]\n",
    "        result_point[:3] = T.dot(point_homogeneous)[:3]\n",
    "        transformed_points.append(result_point)\n",
    "        \n",
    "    return np.array(transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuScenesDataloader:\n",
    "    def __init__(self, nusc, data_dir: Path, sequence: int,  nusc_version: str = \"v1.0-mini\", *_, **__):\n",
    "        try:\n",
    "            importlib.import_module(\"nuscenes\")\n",
    "        except ModuleNotFoundError:\n",
    "            print(\"nuscenes-devkit is not installed on your system\")\n",
    "            print('run \"pip install nuscenes-devkit\"')\n",
    "            sys.exit(1)\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.sequence_id = str(int(sequence)).zfill(4)\n",
    "        self.sequence = self.sequence_id\n",
    "\n",
    "        if nusc is None:\n",
    "            raise \"No NuScenes dataset provided\"\n",
    "        \n",
    "        self.nusc = nusc\n",
    "        self.scene_name = f\"scene-{self.sequence_id}\"\n",
    "        \n",
    "        # Get the scene\n",
    "        self.scene = None\n",
    "        for s in self.nusc.scene:\n",
    "           if self.scene_name == s[\"name\"]:\n",
    "               self.scene = s\n",
    "        \n",
    "        if  self.scene is None:\n",
    "            print(f'[ERROR] Sequence \"{self.sequence_id}\" not available scenes')\n",
    "            print(\"\\nAvailable scenes:\")\n",
    "            self.nusc.list_scenes()\n",
    "            sys.exit(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def doppler_v(pts, vx_idx, vy_idx):\n",
    "        # pts: [x y z dyn_prop id rcs vx vy vx_comp vy_comp ...]\n",
    "        # Compute the Doppler shift for each point\n",
    "        x, y, vx, vy = pts[:, 0], pts[:, 1], pts[:, vx_idx], pts[:, vy_idx]\n",
    "        v_doppler = (vx*x + vy*y) / np.sqrt(x**2 + y**2)\n",
    "\n",
    "        return v_doppler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuScenesMultipleRadarMultiSweeps(NuScenesDataloader):\n",
    "    def __init__(self, \n",
    "                 nusc,\n",
    "                 data_dir: Path,\n",
    "                 sequence: int,\n",
    "                 seq_crop_indices: list = [],\n",
    "                 nsweeps = 5,\n",
    "                 sensors: list= [],\n",
    "                 filter_dynamic_pts=False,\n",
    "                 sps_labels_dir=None,\n",
    "                 sps_thresh=0.6,\n",
    "                 apply_dpr = False,\n",
    "                 ransac_threshold = 0.1,\n",
    "                 ref_sensor='LIDAR_TOP',\n",
    "                 ref_frame=None,\n",
    "                 measure_range = 100,\n",
    "                 nusc_version: str = \"v1.0-mini\",\n",
    "                 annotated_keyframes: bool = False, *_, **__):\n",
    "        \"\"\"\n",
    "        Initializer for the NuScenes Radar and LIDAR synchronized dataset\n",
    "\n",
    "        Args:\n",
    "            data_dir (Path): Location of the NuScenes dataset\n",
    "            sequence (int): Sequence ID\n",
    "            mode (str, optional): Do we want radar or LIDAR data?.  Defaults to \"lidar\".\n",
    "            sensor_name (str, optional): Sensor name from the dataset: \n",
    "            front_only (bool, optional): Do we want only data from the front radar?\n",
    "        \"\"\"\n",
    "        if len(sensors) == 0:\n",
    "            raise ValueError(\"No sensors selected\")\n",
    "        super().__init__(nusc, data_dir, sequence, \"radar\", nusc_version)\n",
    "\n",
    "        self.sensors = sensors\n",
    "        self.ref_sensor = ref_sensor\n",
    "        self.channels = [\"RADAR_FRONT\", \"RADAR_FRONT_LEFT\", \"RADAR_FRONT_RIGHT\", \"RADAR_BACK_LEFT\", \"RADAR_BACK_RIGHT\"]\n",
    "\n",
    "        self.ref_frame = ref_frame\n",
    "\n",
    "        self.seq_crop_indices = seq_crop_indices # Keep between of these frames only\n",
    "        assert(nsweeps > 0), \"Number of sweeps should be >= 1\"\n",
    "        self.n_sweeps = nsweeps\n",
    "        self.measure_range = measure_range\n",
    "\n",
    "        self.ransac_solver = RANSACSolver(ransac_threshold)\n",
    "        self.apply_dpr = apply_dpr\n",
    "        self.filter_dynamic_pts = filter_dynamic_pts\n",
    "        self.sps_labels_dir = sps_labels_dir\n",
    "        self.sps_thresh = sps_thresh\n",
    "        self.min_distance = 1.0 # For Multi-sweep reading\n",
    "\n",
    "        \n",
    "        if annotated_keyframes:\n",
    "            self.sensor_readings, self.num_readings = self._get_annotated_sensor_readings(self.sensors)\n",
    "            self.cam_readings = self._get_annotated_sensor_readings([\"CAM_FRONT\"])[0][\"CAM_FRONT\"]\n",
    "        else:\n",
    "            self.sensor_readings, self.num_readings = self._get_sensor_readings()\n",
    "        \n",
    "        self.gt_poses = self._load_poses()\n",
    "        self.local_poses = clear_z(self._load_poses(global_poses=False))\n",
    "        self.global_poses = clear_z(self._load_poses(global_poses=True))\n",
    "        self.timestamps = self._get_timestamps()[:len(self.gt_poses)]\n",
    "        \n",
    "        self.frame_data, self.valid_sample_tokens, self.valid_frame_indices  = self._read_frames_multisweeps()\n",
    "        \n",
    "        self.gt_poses = [p for i,p in enumerate(self.gt_poses) if i in self.valid_frame_indices]\n",
    "        self.local_poses = [p for i,p in enumerate(self.local_poses) if i in self.valid_frame_indices]\n",
    "        self.global_poses = [p for i,p in enumerate(self.global_poses) if i in self.valid_frame_indices]\n",
    "        self.timestamps = [p for i,p in enumerate(self.timestamps) if i in self.valid_frame_indices]\n",
    "        self.gt_poses_global = np.array(self.global_poses)\n",
    "        self.num_readings = len(self.valid_frame_indices)\n",
    "\n",
    "\n",
    "        self.image_width = 1600\n",
    "        self.image_height = 9000\n",
    "        self.h_fov_deg = 70\n",
    "        self.v_fov_deg = 44\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_readings\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.ref_frame == self.ref_sensor and self.ref_frame is not None:\n",
    "            sensors = [self.ref_sensor]\n",
    "        else:\n",
    "            sensors = self.sensors\n",
    "        return self.read_point_clouds(idx), self.read_calibs(idx), sensors, self.read_timestamps(idx)\n",
    "    \n",
    "    \n",
    "    def read_point_clouds(self, idx):\n",
    "        pointclouds = []\n",
    "        \n",
    "        frame_dict = self.frame_data[idx]\n",
    "        pcd = frame_dict['points']\n",
    "        sensor_ids = frame_dict['sensor_ids']\n",
    "        calibs = self.read_calibs(idx)\n",
    "        global_from_car = self.global_poses[idx]\n",
    "\n",
    "        parsed_points = None\n",
    "\n",
    "        if self.ref_frame == self.ref_sensor and self.ref_frame is not None:\n",
    "            # Just return the reference sensor pcd\n",
    "            points = pcd[self.ref_sensor]\n",
    "            pointcloud_reformatted = np.zeros((len(points), 6))\n",
    "            pointcloud_reformatted[:, :3] = points[:, :3] # x y z\n",
    "            pointcloud_reformatted[:, 3] = points[:, 3] # rcs\n",
    "            pointcloud_reformatted[:, 4]   = self.doppler_v(points, 5, 6) # doppler_shift\n",
    "            pointcloud_reformatted[:, 5]   = self.doppler_v(points, 7, 8) # compensated velocities doppler shift\n",
    "            parsed_points = [pointcloud_reformatted.astype(np.float64)]\n",
    "        elif self.ref_frame is None:\n",
    "            # Output each pointcloud in its own sensor frame\n",
    "            for sensor in self.sensors:\n",
    "                points = pcd[sensor]\n",
    "                pointcloud_reformatted = np.zeros((len(points), 6))\n",
    "                pointcloud_reformatted[:, :3] = points[:, :3] # x y z\n",
    "                pointcloud_reformatted[:, 3] = points[:, 3] # rcs\n",
    "                pointcloud_reformatted[:, 4]   = self.doppler_v(points, 5, 6) # doppler_shift\n",
    "                pointcloud_reformatted[:, 5]   = self.doppler_v(points, 7, 8) # compensated velocities doppler shift\n",
    "                pointclouds.append(pointcloud_reformatted.astype(np.float64))\n",
    "            parsed_points = pointclouds\n",
    "        \n",
    "        elif self.ref_frame == 'ego':\n",
    "            # Transform pointcloud to the ego vehicle frame for each sensor and stack them\n",
    "            for sensor, car_from_sensor in zip(self.sensors, calibs):\n",
    "                points = pcd[sensor]\n",
    "                pointcloud_reformatted = np.zeros((len(points), 6))\n",
    "                pointcloud_reformatted[:, :3] = points[:, :3] # x y z\n",
    "                pointcloud_reformatted[:, 3] = points[:, 3] # rcs\n",
    "                pointcloud_reformatted[:, 4]   = self.doppler_v(points, 5, 6) # doppler_shift\n",
    "                pointcloud_reformatted[:, 5]   = self.doppler_v(points, 7, 8) # compensated velocities doppler shift\n",
    "                ego_points = transform_doppler_points(car_from_sensor, pointcloud_reformatted.astype(np.float64))\n",
    "                pointclouds.append(ego_points)\n",
    "            parsed_points = np.vstack(pointclouds)\n",
    "        elif self.ref_frame == 'global':\n",
    "            for sensor, car_from_sensor in zip(self.sensors, calibs):\n",
    "                points = pcd[sensor]\n",
    "                pointcloud_reformatted = np.zeros((len(points), 6))\n",
    "                pointcloud_reformatted[:, :3] = points[:, :3] # x y z\n",
    "                pointcloud_reformatted[:, 3] = points[:, 3] # rcs\n",
    "                pointcloud_reformatted[:, 4]   = self.doppler_v(points, 5, 6) # doppler_shift\n",
    "                pointcloud_reformatted[:, 5]   = self.doppler_v(points, 7, 8) # compensated velocities doppler shift\n",
    "                ego_points = transform_doppler_points(car_from_sensor, pointcloud_reformatted.astype(np.float64))\n",
    "                global_points = transform_doppler_points(global_from_car, ego_points)\n",
    "                pointclouds.append(global_points)\n",
    "            parsed_points = np.vstack(pointclouds)\n",
    "\n",
    "        if self.sps_labels_dir is not None:\n",
    "            # Label and filter points\n",
    "            labelled_map_path = os.path.join(self.sps_labels_dir, f'scene-{self.sequence_id}.asc')\n",
    "            lmap = np.loadtxt(labelled_map_path, delimiter=' ', skiprows=1)\n",
    "\n",
    "            def get_sps_labels(map, scan_points):\n",
    "                labeled_map_points = map[:, :3]\n",
    "                labeled_map_labels = map[:, -1]\n",
    "\n",
    "                sps_labels = []\n",
    "                for point in scan_points[:, :3]:\n",
    "                    distances = np.linalg.norm(labeled_map_points - point, axis=1)\n",
    "                    closest_point_idx = np.argmin(distances)\n",
    "                    sps_labels.append(labeled_map_labels[closest_point_idx])\n",
    "                sps_labels = np.array(sps_labels)\n",
    "                return sps_labels\n",
    "\n",
    "            if self.ref_frame is None:\n",
    "                # Need to extract labels for each sensor's points \n",
    "                filtered_pcds = []\n",
    "                for sensor in self.sensors:\n",
    "                    s_idx = self.sensors.index(sensor)\n",
    "                    sensor_pcd = parsed_points[s_idx]\n",
    "                    ego_sensor_pcd = transform_doppler_points(calibs[s_idx], sensor_pcd)\n",
    "                    global_sensor_pcd = transform_doppler_points(global_from_car, ego_sensor_pcd)\n",
    "                    sensor_pcd_labels = get_sps_labels(lmap, global_sensor_pcd)\n",
    "                    sps_filtered_pcd = sensor_pcd[sensor_pcd_labels >= self.sps_thresh]\n",
    "                    # print(f\"Before: {len(sensor_pcd)} | After {len(sps_filtered_pcd)}\")\n",
    "                    if len(sps_filtered_pcd) == 0:\n",
    "                        filtered_pcds.append(sensor_pcd.astype(np.float64))\n",
    "                    else:\n",
    "                        filtered_pcds.append(sps_filtered_pcd.astype(np.float64))\n",
    "                parsed_points = filtered_pcds\n",
    "\n",
    "            elif self.ref_frame in self.sensors:\n",
    "                s_idx = self.sensors.index(self.ref_frame)\n",
    "                sps_filtered_pcd = parsed_points[s_idx]\n",
    "                ego_sensor_pcd = transform_doppler_points(calibs[s_idx], sps_filtered_pcd)\n",
    "                global_sensor_pcd = transform_doppler_points(global_from_car, ego_sensor_pcd)\n",
    "                sps_labels = get_sps_labels(lmap, global_sensor_pcd)\n",
    "                sps_filtered_pcd = sps_filtered_pcd[sps_labels >= self.sps_thresh]\n",
    "                parsed_points = [sps_filtered_pcd.astype(np.float64)]\n",
    "\n",
    "            elif self.ref_frame == 'ego':\n",
    "                sps_filtered_pcd = parsed_points\n",
    "                global_sensor_pcd = transform_doppler_points(global_from_car, sps_filtered_pcd)\n",
    "                sps_labels = get_sps_labels(lmap, global_sensor_pcd)\n",
    "                sps_filtered_pcd = sps_filtered_pcd[sps_labels >= self.sps_thresh]\n",
    "                parsed_points = sps_filtered_pcd.astype(np.float64)\n",
    "            \n",
    "            elif self.ref_frame == 'global':\n",
    "                sps_labels = get_sps_labels(lmap, parsed_points)\n",
    "                sps_filtered_pcd = sps_filtered_pcd[sps_labels >= self.sps_thresh]\n",
    "                parsed_points = sps_filtered_pcd.astype(np.float64)\n",
    "\n",
    "\n",
    "        return parsed_points\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_static_reliable_points(pointcloud):\n",
    "        \"\"\"\n",
    "        Filters radar pointcloud data to keep the most reliable static points.\n",
    "        \n",
    "        :param pointcloud: <np.float: d, n>. Point cloud matrix with d dimensions and n points.\n",
    "        :return: Filtered point cloud matrix.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define the states to keep\n",
    "        invalid_states_to_keep = [0,4,8,9,10,11,12,15,16,17]\n",
    "        dynprop_states_to_keep = [1, 3, 5, 7]\n",
    "        ambig_states_to_keep = [3]\n",
    "        \n",
    "        # Extract relevant fields from the point cloud data\n",
    "        dyn_prop = pointcloud[3, :]\n",
    "        invalid_state = pointcloud[15, :]\n",
    "        ambig_state = pointcloud[11, :]\n",
    "\n",
    "        # Create a boolean mask for each condition\n",
    "        mask_dynprop = np.isin(dyn_prop, dynprop_states_to_keep)\n",
    "        mask_invalid = np.isin(invalid_state, invalid_states_to_keep)\n",
    "        mask_ambig = np.isin(ambig_state, ambig_states_to_keep)\n",
    "        \n",
    "        # Combine masks to filter points that satisfy all conditions\n",
    "        combined_mask = mask_dynprop & mask_invalid & mask_ambig\n",
    "        # Filter the point cloud\n",
    "        filtered_pointcloud = pointcloud[:, combined_mask]\n",
    "        \n",
    "        return filtered_pointcloud\n",
    "    \n",
    "    def _read_frames_multisweeps(self):\n",
    "        \"\"\"\n",
    "        Reads radar data and processes it into frames.\n",
    "\n",
    "        Args:\n",
    "            merge_into_ref_sensor (bool): If True, merge data from all sensors into ref_sensor coordinate frame.\n",
    "                                        If False, keep point clouds from each sensor separate.\n",
    "\n",
    "        Returns:\n",
    "            List of frames.\n",
    "        \"\"\"\n",
    "        def process_sweeps(start_index, n_sweeps):\n",
    "            current_frame = {}\n",
    "            sensor_ids = []\n",
    "            pcd_dict = {sensor: np.zeros((0, 10)) for sensor in self.channels}  # Dictionary to store point clouds for each sensor\n",
    "\n",
    "            for sensor in self.channels:\n",
    "                points = np.zeros((RadarPointCloud.nbr_dims(), 0))\n",
    "                all_pc = RadarPointCloud(points)\n",
    "                all_times = np.zeros((1, 0))\n",
    "\n",
    "                if self.ref_sensor is None:\n",
    "                    # Use the sensor itself\n",
    "                    ref_chan = sensor\n",
    "                else:\n",
    "                    ref_chan = self.ref_sensor\n",
    "                    \n",
    "                ref_sample_data = self.sensor_readings[ref_chan][start_index]\n",
    "                ref_time = 1e-6 * ref_sample_data['timestamp']\n",
    "                ref_pose_rec = self.nusc.get('ego_pose', ref_sample_data['ego_pose_token'])\n",
    "                ref_cs_rec = self.nusc.get('calibrated_sensor', ref_sample_data['calibrated_sensor_token'])\n",
    "                ref_from_car = transform_matrix(ref_cs_rec['translation'], Quaternion(ref_cs_rec['rotation']), inverse=True)\n",
    "                car_from_global = transform_matrix(ref_pose_rec['translation'], Quaternion(ref_pose_rec['rotation']), inverse=True)\n",
    "\n",
    "\n",
    "                current_sample_data = self.sensor_readings[sensor][start_index]\n",
    "                ext_nbr_points = []\n",
    "\n",
    "                # print(f\"Processing index: {start_index} | Sweep indices: \", end=\"\")\n",
    "                for j in range(n_sweeps):\n",
    "                    current_index = start_index - j\n",
    "                    if current_index < 0:\n",
    "                        break\n",
    "\n",
    "                    # print(current_index, end=\", \")\n",
    "\n",
    "                    # invalid_states_to_keep = [0x00, 0x04, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0f, 0x10, 0x11]\n",
    "                    invalid_states_to_keep = [0,4,8,9,10,11,12,15,16,17]\n",
    "                    dynprop_states_to_keep = [1, 3, 5, 7]\n",
    "                    ambig_states_to_keep = [3]\n",
    "                    if self.filter_dynamic_pts:\n",
    "                        current_pc = RadarPointCloud.from_file(osp.join(self.nusc.dataroot,\n",
    "                                                                        current_sample_data['filename']),\n",
    "                                                                        invalid_states=invalid_states_to_keep,\n",
    "                                                                        dynprop_states=dynprop_states_to_keep, ambig_states=ambig_states_to_keep)\n",
    "                    else:\n",
    "                        current_pc = RadarPointCloud.from_file(osp.join(self.nusc.dataroot,\n",
    "                                                                        current_sample_data['filename']),\n",
    "                                                                        invalid_states=range(18),\n",
    "                                                                        dynprop_states=range(8), ambig_states=range(5))\n",
    "                    current_pc.remove_close(self.min_distance)\n",
    "                    \n",
    "\n",
    "                    # Transform to reference channel\n",
    "                    if self.ref_sensor is not None and self.ref_frame in self.sensors:\n",
    "                        current_pose_rec = self.nusc.get('ego_pose', current_sample_data['ego_pose_token'])\n",
    "                        global_from_car = transform_matrix(current_pose_rec['translation'], Quaternion(current_pose_rec['rotation']), inverse=False)\n",
    "                        current_cs_rec = self.nusc.get('calibrated_sensor', current_sample_data['calibrated_sensor_token'])\n",
    "                        car_from_current = transform_matrix(current_cs_rec['translation'], Quaternion(current_cs_rec['rotation']), inverse=False)\n",
    "                        trans_matrix = reduce(np.dot, [ref_from_car, car_from_global, global_from_car, car_from_current])\n",
    "                        current_pc.transform(trans_matrix)\n",
    "\n",
    "                    time_lag = ref_time - 1e-6 * current_sample_data['timestamp']\n",
    "                    times = time_lag * np.ones((1, current_pc.nbr_points()))\n",
    "                    all_times = np.hstack((all_times, times))\n",
    "                    all_pc.points = np.hstack((all_pc.points, current_pc.points))\n",
    "                    ext_nbr_points.append(current_pc.points.shape[1])\n",
    "\n",
    "                    if current_index > 0:\n",
    "                        current_sample_data = self.sensor_readings[sensor][current_index]\n",
    "                # print()\n",
    "                radar_pc = all_pc\n",
    "                times = all_times\n",
    "                nbr_points = np.array(ext_nbr_points)\n",
    "\n",
    "                ## Filter points\n",
    "                # radar_pc = self.filter_static_reliable_points(radar_pc.points)\n",
    "                radar_pc = radar_pc.points\n",
    "                radar_points = np.zeros((9, radar_pc.shape[1]))\n",
    "                \n",
    "                radar_points[:3, :] = radar_pc[:3, :]\n",
    "                radar_points[3, :] = radar_pc[5, :]\n",
    "                radar_points[4, :] = radar_pc[4, :]\n",
    "                radar_points[5:7, :] = radar_pc[6:8, :]\n",
    "                radar_points[7:9, :] = radar_pc[8:10, :]\n",
    "                radar_points = radar_points.T\n",
    "                radar_points = np.hstack((radar_points, times.transpose()))\n",
    "\n",
    "                if self.apply_dpr and radar_points.shape[0] > 1:\n",
    "                    nbr_flag = np.cumsum(nbr_points)\n",
    "                    pcl_list = np.split(radar_points, nbr_flag, axis=0)\n",
    "                    pcls_new = np.zeros((0, 10))\n",
    "                    for index, pcl in enumerate(pcl_list[:-1]):\n",
    "                        if pcl.shape[0] > 1:\n",
    "                            info = [\n",
    "                                [self.sequence_id, current_index],\n",
    "                                sensor,\n",
    "                                nbr_points[0]\n",
    "                            ]\n",
    "                            best_mask, _, _ = self.ransac_solver.ransac_nusc(pcl, vis=False, info=info)\n",
    "                            if best_mask is not None:\n",
    "                                pcl = pcl[best_mask]\n",
    "                        pcls_new = np.vstack((pcls_new, pcl))\n",
    "                    radar_points = pcls_new\n",
    "\n",
    "                pcd_dict[sensor] = np.concatenate((pcd_dict[sensor], radar_points), axis=0)\n",
    "                sensor_ids.extend([sensor] * len(radar_points))\n",
    "\n",
    "            pose = np.empty((4, 4), dtype=np.float32)\n",
    "            pose_record = self.nusc.get(\"ego_pose\", ref_sample_data[\"ego_pose_token\"])\n",
    "            pose[:, :] = transform_matrix(\n",
    "                pose_record[\"translation\"],\n",
    "                Quaternion(pose_record[\"rotation\"]),\n",
    "            )\n",
    "\n",
    "            current_frame = {\n",
    "                'points': pcd_dict,\n",
    "                'gt_pose': pose,\n",
    "                'position': pose[:2, 3].reshape(1, -1),\n",
    "                'timestamp': ref_sample_data['timestamp'],\n",
    "                'sensor_ids': np.array(sensor_ids),\n",
    "            }\n",
    "\n",
    "            frames.append(current_frame)\n",
    "            valid_indices.append(start_index)\n",
    "\n",
    "        frames = []\n",
    "        valid_indices = []\n",
    "        valid_tokens = []\n",
    "\n",
    "        # Process full sweeps\n",
    "        for i in range(self.n_sweeps - 1, self.num_readings, self.n_sweeps):\n",
    "            process_sweeps(i, self.n_sweeps)\n",
    "\n",
    "        # Process remaining sweeps\n",
    "        remaining = self.num_readings % self.n_sweeps\n",
    "        if remaining > 0:\n",
    "            process_sweeps(self.num_readings - 1, remaining)\n",
    "\n",
    "        sorted_frames = sorted(frames, key=lambda t: t['timestamp'])\n",
    "        frames = list(sorted_frames)\n",
    "        for frame in frames:\n",
    "            frame['day'] = (frame['timestamp'] - sorted_frames[0]['timestamp']) / (1e6 * 3600 * 24)\n",
    "        return frames, valid_tokens, valid_indices\n",
    "\n",
    "\n",
    "    def read_calibs(self, idx):\n",
    "        if self.ref_frame == self.ref_sensor and self.ref_frame is not None:\n",
    "            calib = self.nusc.get('calibrated_sensor', self.sensor_readings[self.ref_sensor][idx]['calibrated_sensor_token'])\n",
    "            sensor_to_car = transform_matrix(calib['translation'], Quaternion(calib['rotation']), inverse=False)\n",
    "            return [sensor_to_car]\n",
    "        else:\n",
    "            calibs = []\n",
    "            for sensor in self.sensors:\n",
    "                calib = self.nusc.get('calibrated_sensor', self.sensor_readings[sensor][idx]['calibrated_sensor_token'])\n",
    "                sensor_to_car = transform_matrix(calib['translation'], Quaternion(calib['rotation']), inverse=False)\n",
    "                calibs.append(sensor_to_car)\n",
    "            \n",
    "            return calibs\n",
    "    \n",
    "\n",
    "    def read_timestamps(self, idx):\n",
    "        timestamp = np.array(self.timestamps[idx])\n",
    "        return timestamp\n",
    "    \n",
    "    \n",
    "    def _load_poses(self, global_poses=False) -> np.ndarray:\n",
    "        poses = []\n",
    "        sensors = self.sensors\n",
    "       \n",
    "        for idx in range(self.num_readings):\n",
    "            current_pose_dict = {}\n",
    "            for sensor in sensors:\n",
    "                current_pose_dict[sensor] = {}\n",
    "                current_sensor_reading = self.sensor_readings[sensor][idx]\n",
    "\n",
    "                current_pose_reading = self.nusc.get(\"ego_pose\", current_sensor_reading[\"ego_pose_token\"])\n",
    "                pose_matrix = transform_matrix(\n",
    "                    current_pose_reading[\"translation\"],\n",
    "                    Quaternion(current_pose_reading[\"rotation\"]),\n",
    "                )\n",
    "                current_pose_dict[sensor]['pose'] = pose_matrix\n",
    "                current_pose_dict[sensor]['timestamp'] = current_pose_reading['timestamp']\n",
    "                # print(current_pose_reading['timestamp'])\n",
    "                # print(pose_matrix)\n",
    "            \n",
    "            sorted_result = sorted(list(current_pose_dict.items()), key=lambda t:t[1]['timestamp'])\n",
    "            current_pose_dict = {}\n",
    "            current_pose_dict.update(sorted_result)\n",
    "            latest_pose = current_pose_dict[list(current_pose_dict.keys())[-1]]['pose']\n",
    "            poses.append(np.expand_dims(latest_pose, axis=0))\n",
    "        \n",
    "        poses = np.concatenate(poses, axis=0)\n",
    "        # Convert from global coordinate poses to local poses\n",
    "        \n",
    "        first_pose = poses[0, :, :]\n",
    "        \n",
    "        if not global_poses:\n",
    "            poses = np.linalg.inv(first_pose) @ poses\n",
    "\n",
    "        return poses\n",
    "    \n",
    "    def _to_seconds(self, t):\n",
    "        return datetime.datetime.fromtimestamp(t * 1e-6).timestamp()\n",
    "    \n",
    "    def _get_timestamps(self):\n",
    "        timestamps = {}\n",
    "        for sensor in self.sensors:\n",
    "            timestamps[sensor] = [d['timestamp'] for d in self.sensor_readings[sensor]]    \n",
    "\n",
    "        timestamps_combined = []\n",
    "        for i in range(self.num_readings):\n",
    "            timestamps_combined.append([self._to_seconds(timestamps[sensor][i]) for sensor in self.sensors])\n",
    "\n",
    "        return timestamps_combined\n",
    "    \n",
    "    \n",
    "    def _get_sensor_readings(self) -> dict:\n",
    "        \n",
    "        # Get first annotated sample, then iterate starting from it\n",
    "        current_sample_token = self.scene['first_sample_token']\n",
    "        \n",
    "        current_sample = self.nusc.get('sample', current_sample_token)\n",
    "        if self.ref_sensor not in self.channels and self.ref_sensor is not None:\n",
    "            channels = self.channels + [self.ref_sensor]\n",
    "        else:\n",
    "            channels = self.channels\n",
    "\n",
    "        sensor_readings = {}\n",
    "        for sensor in channels:\n",
    "            sensor_readings[sensor] = []\n",
    "            \n",
    "        # Combine all sensor readings into a single list and sort using timestamps\n",
    "        all_combined = []\n",
    "\n",
    "        for sensor in channels:\n",
    "            sensor_data_token = current_sample['data'][sensor]\n",
    "            sensor_data = self.nusc.get('sample_data', sensor_data_token)\n",
    "\n",
    "            while sensor_data['next'] != '':\n",
    "                all_combined.append(sensor_data)\n",
    "                sensor_data_token = sensor_data['next']\n",
    "                sensor_data = self.nusc.get('sample_data', sensor_data_token)\n",
    "\n",
    "        all_combined_sorted = sorted(all_combined, key=lambda d: d['timestamp'])\n",
    "\n",
    "        # Extract blocks of sensor readings from the sorted list\n",
    "        current_sensor_readings = {}\n",
    "        \n",
    "        for sensor in channels:\n",
    "            current_sensor_readings[sensor] = []\n",
    "            \n",
    "        sample_tokens = []\n",
    "        for sensor_reading in all_combined_sorted:\n",
    "            # If it doesn't exist. Store sensor readings to current block\n",
    "            if not current_sensor_readings[sensor_reading['channel']]:\n",
    "                current_sensor_readings[sensor_reading['channel']] = sensor_reading\n",
    "                sample_tokens.append(sensor_reading['sample_token'])\n",
    "\n",
    "            # If we have a reading from all sensors\n",
    "            if all(list(current_sensor_readings.values())):\n",
    "                for key in current_sensor_readings.keys():\n",
    "                    # Double check the readings are associated to the same sample token\n",
    "                    if sample_tokens.count(sample_tokens[0]) == len(sample_tokens):\n",
    "                        # Store all the readings for this block\n",
    "                        sensor_readings[key].append(current_sensor_readings[key])\n",
    "                    # Reset to read a new block\n",
    "                    current_sensor_readings[key] = {}\n",
    "\n",
    "                sample_tokens = []\n",
    "             \n",
    "        num_readings = len(sensor_readings[list(sensor_readings.keys())[-1]])\n",
    "        \n",
    "        return sensor_readings, num_readings, \n",
    "\n",
    "    def _get_annotated_sensor_readings(self, sensors) -> dict:\n",
    "        sensor_readings = {}\n",
    "        for sensor in sensors:\n",
    "            first_sample_token = self.scene['first_sample_token']\n",
    "            sample = self.nusc.get('sample', first_sample_token)\n",
    "            sensor_readings[sensor] = []\n",
    "            \n",
    "            while sample[\"next\"] != \"\":\n",
    "                sensor_data_token = sample[\"data\"][sensor]\n",
    "\n",
    "                sensor_data = self.nusc.get('sample_data', sensor_data_token)\n",
    "                sensor_readings[sensor].append(sensor_data)\n",
    "                sample = self.nusc.get('sample', sample['next'])\n",
    "                \n",
    "\n",
    "        num_readings = len(sensor_readings[list(sensor_readings.keys())[-1]])\n",
    "\n",
    "        return sensor_readings, num_readings\n",
    "            \n",
    "\n",
    "    def plot_ego_trajectory_with_radar(self, idx):\n",
    "        \"\"\"\n",
    "        Plots the ego trajectory with radar point clouds for a given index.\n",
    "        \n",
    "        Args:\n",
    "        idx (int): The index for which to plot the data.\n",
    "        \"\"\"\n",
    "        # Extract ego positions\n",
    "        ego_positions = np.array([pose[:3, 3] for pose in self.global_poses])\n",
    "        # Calculate time elapsed in seconds from the first timestamp\n",
    "        first_timestamp = self.timestamps[0][0]\n",
    "        time_elapsed = [(t[0] - first_timestamp) for t in self.timestamps]\n",
    "        # timestamps = [t[0] for t in self.timestamps]\n",
    "\n",
    "        # Create the plot\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "        # Plot the ego trajectory\n",
    "        axes[0].plot(ego_positions[:, 0], ego_positions[:, 1], marker='o', linestyle='-', color='b')\n",
    "        axes[0].plot(ego_positions[idx, 0], ego_positions[idx, 1], marker='o', color='r', markersize=10)\n",
    "        axes[0].set_xlabel('X Position')\n",
    "        axes[0].set_ylabel('Y Position')\n",
    "        axes[0].set_title('Ego Positions (X-Y Plane)')\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # Plot the radar point clouds\n",
    "        pointclouds, _, _, timestamp = self[idx]\n",
    "        all_points = np.concatenate(pointclouds, axis=0)\n",
    "        scatter = axes[1].scatter(all_points[:, 0], all_points[:, 1], s=1)\n",
    "        axes[1].set_xlabel('X Position')\n",
    "        axes[1].set_ylabel('Y Position')\n",
    "        axes[1].set_title('Radar Point Clouds')\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        # Add timestamp text\n",
    "        elapsed_time = time_elapsed[idx]\n",
    "        timestamp_text = axes[1].text(0.05, 0.95, f'Time Elapsed: {elapsed_time:.2f} seconds', transform=axes[1].transAxes, verticalalignment='top')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipeline\n",
    "\n",
    "Testing on a single row of the matched scenes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/umair/workspace/datasets/nuscenes_radar/\"\n",
    "sensors = [\"RADAR_FRONT\", \"RADAR_FRONT_LEFT\", \"RADAR_FRONT_RIGHT\", \"RADAR_BACK_LEFT\", \"RADAR_BACK_RIGHT\"]\n",
    "versions = {'trainval': 'v1.0-trainval', 'test': 'v1.0-test'}\n",
    "nuscenes_exp = {\n",
    "    vname : NuScenes(dataroot=data_dir, version=version, verbose=False)\\\n",
    "    for vname,version in versions.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_df = pd.read_json('sps_ortsim_nuscenes_df.json')\n",
    "sps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_df['min_mean_distance'] = sps_df['closest_scenes_data'].apply(lambda x: min([e['mean_distance'] for e in x.values()]))\n",
    "sps_df['max_ort_sim'] = sps_df['closest_scenes_data'].apply(lambda x: -max([e['trajectory_similarity'] for e in x.values()]))\n",
    "sorted_sps_df = sps_df.sort_values(['min_mean_distance', 'max_ort_sim'], ascending=True)\n",
    "sorted_sps_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = sps_df[sps_df.scene_name == 'scene-0151'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_scene_name = row['scene_name']\n",
    "ref_split = row['split']\n",
    "closest_scenes = row['closest_scenes_data']\n",
    "ref_frame = 'global'\n",
    "num_sweeps = 5\n",
    "ref_sensor = None\n",
    "apply_dpr = True\n",
    "filter_points = False\n",
    "dpr_thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## We keep track of frames where the ego poses of the scenes highly overlap\n",
    "# ## So we want to use these frames to build maps\n",
    "# ## NOTE: These are tied with the nsweeps when generating the SPS dataframe\n",
    "# matched_frame_indices = {ref_scene_name : []}\n",
    "# for scene, data in closest_scenes.items():\n",
    "#     matched_indices = data['matching_indices']\n",
    "#     ref_indices = [t[1] for t in matched_indices]\n",
    "#     scene_indices = [t[0] for t in matched_indices]\n",
    "#     matched_frame_indices[ref_scene_name].extend(ref_indices)\n",
    "#     matched_frame_indices[scene] = scene_indices\n",
    "\n",
    "# frame_ranges = {name : (min(values), max(values)) for name,values in matched_frame_indices.items()}\n",
    "# frame_ranges   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Dataloader for each scene in a record\n",
    "dataloaders = {ref_scene_name : NuScenesMultipleRadarMultiSweeps(\n",
    "    data_dir=data_dir,\n",
    "    nusc=nuscenes_exp[ref_split],\n",
    "    sequence=int(ref_scene_name.split(\"-\")[-1]),\n",
    "    sensors=sensors,\n",
    "    nsweeps=num_sweeps,\n",
    "    ref_frame=ref_frame,\n",
    "    ref_sensor=ref_sensor,\n",
    "    apply_dpr=apply_dpr,\n",
    "    filter_points=filter_points,\n",
    "    ransac_threshold=dpr_thresh\n",
    "\n",
    ")}\n",
    "\n",
    "for matched_scene, data in closest_scenes.items():\n",
    "    dataloaders[matched_scene] = NuScenesMultipleRadarMultiSweeps(\n",
    "    data_dir=data_dir,\n",
    "    nusc=nuscenes_exp[data['split']],\n",
    "    sequence=int(matched_scene.split(\"-\")[-1]),\n",
    "    sensors=sensors,\n",
    "    nsweeps=num_sweeps,\n",
    "    ref_frame=ref_frame,\n",
    "    ref_sensor=ref_sensor,\n",
    "    apply_dpr=apply_dpr,\n",
    "    filter_points=filter_points,\n",
    "    ransac_threshold=dpr_thresh\n",
    ")\n",
    "\n",
    "dataloaders.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the PCL where the ego poses overlap\n",
    "# scene_maps = {name : np.vstack([dl[i][0] for i in range(*frame_ranges[name])]) for name,dl in dataloaders.items()}\n",
    "## Use All frames\n",
    "scene_maps = {name : np.vstack([dl[i][0] for i in range(dl.num_readings)]) for name,dl in dataloaders.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_poses = {name: dl.global_poses for name,dl in dataloaders.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_maps(scene_maps, poses, size=0.5, zoom_level=3):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    colors = ['cyan', 'magenta', 'yellow', 'black', 'purple', 'brown']\n",
    "    markers = ['o', 'v', 's', 'P', 'X', 'D']\n",
    "    positions = {name: np.array(pose)[:, :3,3] for name,pose in poses.items()}\n",
    "\n",
    "    for idx, (scene_name, map) in enumerate(scene_maps.items()):\n",
    "        plt.scatter(map[:, 0], map[:, 1], s=size, label=scene_name, alpha=0.5)\n",
    "\n",
    "\n",
    "        if scene_name in positions:\n",
    "            pose = np.array(positions[scene_name])\n",
    "            plt.plot(pose[:, 0], pose[:, 1], label=f'{scene_name} Trajectory', color=colors[idx % len(colors)])\n",
    "            # plt.scatter(pose[:, 0], pose[:, 1], c=colors[idx % len(colors)], marker=markers[idx % len(markers)])\n",
    "            \n",
    "            for i in range(1, len(pose)):\n",
    "                plt.arrow(pose[i-1, 0], pose[i-1, 1], pose[i, 0] - pose[i-1, 0], pose[i, 1] - pose[i-1, 1], \n",
    "                          head_width=0.5, head_length=0.5, fc=colors[idx % len(colors)], ec=colors[idx % len(colors)])\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "\n",
    "    if zoom_level != -1:\n",
    "        all_pos = np.concatenate(list(positions.values()))\n",
    "        x_mean = np.mean(all_pos[:,0])\n",
    "        y_mean = np.mean(all_pos[:,1])\n",
    "        x_std = np.std(all_pos[:,0])\n",
    "        y_std = np.std(all_pos[:,1])\n",
    "        \n",
    "        std_dev_range = zoom_level\n",
    "\n",
    "        x_limits = [x_mean - std_dev_range*x_std, x_mean + std_dev_range*x_std]\n",
    "        y_limits = [y_mean - std_dev_range*y_std, y_mean + std_dev_range*y_std]\n",
    "\n",
    "        plt.xlim(x_limits)\n",
    "        plt.ylim(y_limits)\n",
    "\n",
    "    plt.title(\"Overlapped Maps and Trajectories\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps(scene_maps=scene_maps, poses=scene_poses, zoom_level=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Post-processing\n",
    "Try to see if we can keep points that are in the FOV of all sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_dict = scene_maps\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def convert_to_open3d_pcd(np_points):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np_points[:, :3])\n",
    "    return pcd\n",
    "\n",
    "def align_pointclouds(source, target):\n",
    "    threshold = 0.5\n",
    "    trans_init = np.eye(4)\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    return reg_p2p.transformation\n",
    "\n",
    "def find_overlapping_points(pcd, threshold=0.1):\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    overlapping_indices = set()\n",
    "    points = np.asarray(pcd.points)\n",
    "    for i, point in enumerate(points):\n",
    "        [_, idx, _] = pcd_tree.search_radius_vector_3d(point, threshold)\n",
    "        if len(idx) > 1:\n",
    "            overlapping_indices.add(i)\n",
    "    return overlapping_indices\n",
    "\n",
    "\n",
    "# Convert to Open3D point clouds\n",
    "pcd_dict = {key: convert_to_open3d_pcd(val) for key, val in point_cloud_dict.items()}\n",
    "\n",
    "# Merge point clouds\n",
    "pcd_merged = o3d.geometry.PointCloud()\n",
    "for pcd in pcd_dict.values():\n",
    "    pcd_merged += pcd\n",
    "\n",
    "# Downsample the merged point cloud (optional)\n",
    "# pcd_merged = pcd_merged.voxel_down_sample(voxel_size=0.1)\n",
    "\n",
    "# Align point clouds (pairwise alignment)\n",
    "keys = list(pcd_dict.keys())\n",
    "transforms = {}\n",
    "for i in range(len(keys)):\n",
    "    for j in range(i + 1, len(keys)):\n",
    "        trans_key = f\"{keys[i]}_{keys[j]}\"\n",
    "        transforms[trans_key] = align_pointclouds(pcd_dict[keys[i]], pcd_dict[keys[j]])\n",
    "\n",
    "# Apply transformations\n",
    "for key, trans in transforms.items():\n",
    "    src, tgt = key.split('_')\n",
    "    pcd_dict[src].transform(trans)\n",
    "\n",
    "# Find overlapping points in the merged point cloud\n",
    "overlapping_indices = find_overlapping_points(pcd_merged)\n",
    "\n",
    "# Map overlapping indices back to the original point clouds\n",
    "def get_original_indices(pcd_merged, pcd, overlapping_indices):\n",
    "    merged_points = np.asarray(pcd_merged.points)\n",
    "    pcd_points = np.asarray(pcd.points)\n",
    "    tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    original_indices = set()\n",
    "    for idx in overlapping_indices:\n",
    "        [_, idxs, _] = tree.search_radius_vector_3d(merged_points[idx], 0.1)\n",
    "        original_indices.update(idxs)\n",
    "    return original_indices\n",
    "\n",
    "# Crop individual point clouds to keep only overlapping points and track indices\n",
    "cropped_pcd_dict = {}\n",
    "cropped_indices_dict = {}\n",
    "for key, pcd in pcd_dict.items():\n",
    "    original_indices = get_original_indices(pcd_merged, pcd, overlapping_indices)\n",
    "    overlapping_points = np.asarray(pcd.points)[list(original_indices), :]\n",
    "    cropped_pcd = o3d.geometry.PointCloud()\n",
    "    cropped_pcd.points = o3d.utility.Vector3dVector(overlapping_points)\n",
    "    cropped_pcd_dict[key] = cropped_pcd\n",
    "    cropped_indices_dict[key] = list(original_indices)\n",
    "\n",
    "# Convert Open3D cropped point clouds back to numpy arrays\n",
    "cropped_scene_maps = {key: np.asarray(val.points) for key, val in cropped_pcd_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps(cropped_scene_maps, poses=scene_poses, zoom_level=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dynamic point filter for moving objects using LiDAR GT Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def transfer_labels(labels, radar_points):\n",
    "    \"\"\"\n",
    "    Transfers labels from the labels array to the radar points based on the nearest neighbor search.\n",
    "\n",
    "    Parameters:\n",
    "    labels (np.ndarray): An Nx4 array where each row is (x, y, z, label).\n",
    "    radar_points (np.ndarray): An Mx3 array where each row is (x, y, z).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: An Mx4 array where each row is (x, y, z, label) with labels from the nearest point in the labels array.\n",
    "    \"\"\"\n",
    "    # Extract the coordinates (x, y, z) from the labels array\n",
    "    label_coords = labels[:, :3]\n",
    "\n",
    "    print(np.unique(labels[:, 3], return_counts=True))\n",
    "\n",
    "    # Build a KDTree for efficient nearest neighbor search\n",
    "    tree = KDTree(label_coords)\n",
    "\n",
    "    # Find the nearest neighbors for each radar point\n",
    "    distances, indices = tree.query(radar_points)\n",
    "\n",
    "    # Create an array to store the radar points with their corresponding labels\n",
    "    radar_points_with_labels = np.zeros((radar_points.shape[0], radar_points.shape[1] + 1))\n",
    "\n",
    "    # Copy the radar points to the new array\n",
    "    radar_points_with_labels[:, :3] = radar_points\n",
    "\n",
    "    # Assign the corresponding labels from the labels array\n",
    "    radar_points_with_labels[:, 3] = labels[indices, 3]\n",
    "\n",
    "    print(np.unique(radar_points_with_labels[:, 3], return_counts=True))\n",
    "\n",
    "\n",
    "    return radar_points_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lidar_labelled_maps = {name: transfer_labels(np.load(f'{name}_lidar_labels.npy'), map[:,:3])   for name,map in cropped_scene_maps.items()}\n",
    "# lidar_labels = {name: np.load(f'{name}_lidar_labels.npy') for name,map in cropped_scene_maps.items()}\n",
    "# plot_maps(scene_maps=lidar_labelled_maps, poses=scene_poses, zoom_level=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a prior for dynamic regions using individual scans of each sequence and populating a VoxelGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "class VoxelGrid:\n",
    "    def __init__(self, voxel_size, map_bounds):\n",
    "        self.voxel_size = voxel_size\n",
    "        self.map_bounds = map_bounds\n",
    "        self.grid_shape = (\n",
    "            int((map_bounds[1] - map_bounds[0]) / voxel_size),\n",
    "            int((map_bounds[3] - map_bounds[2]) / voxel_size),\n",
    "            int((map_bounds[5] - map_bounds[4]) / voxel_size)\n",
    "        )\n",
    "        self.voxel_counts = np.zeros(self.grid_shape)\n",
    "    \n",
    "    def point_to_voxel_index(self, point):\n",
    "        ix = int((point[0] - self.map_bounds[0]) / self.voxel_size)\n",
    "        iy = int((point[1] - self.map_bounds[2]) / self.voxel_size)\n",
    "        iz = int((point[2] - self.map_bounds[4]) / self.voxel_size)\n",
    "        return ix, iy, iz\n",
    "    \n",
    "    def update_with_scan(self, point_cloud):\n",
    "        for point in point_cloud:\n",
    "            ix, iy, iz = self.point_to_voxel_index(point)\n",
    "            if 0 <= ix < self.grid_shape[0] and 0 <= iy < self.grid_shape[1] and 0 <= iz < self.grid_shape[2]:\n",
    "                self.voxel_counts[ix, iy, iz] += 1\n",
    "    \n",
    "    def get_normalized_scores(self):\n",
    "        max_count = np.max(self.voxel_counts)\n",
    "        if max_count > 0:\n",
    "            return 1 - (self.voxel_counts / max_count)  # Normalize to [0, 1]\n",
    "        else:\n",
    "            return self.voxel_counts\n",
    "        \n",
    "    def query_point_score(self, point):\n",
    "        ix, iy, iz = self.point_to_voxel_index(point)\n",
    "        if 0 <= ix < self.grid_shape[0] and 0 <= iy < self.grid_shape[1] and 0 <= iz < self.grid_shape[2]:\n",
    "            normalized_scores = self.get_normalized_scores()\n",
    "            return normalized_scores[ix, iy, iz]\n",
    "        else:\n",
    "            return None  # Point is outside the grid bounds\n",
    "        \n",
    "    def assign_scores_to_pointcloud(self, point_cloud):\n",
    "        scores = []\n",
    "        for point in point_cloud:\n",
    "            score = self.query_point_score(point)\n",
    "            scores.append(score)\n",
    "        return np.hstack((point_cloud, np.array(scores).reshape(-1, 1)))\n",
    "\n",
    "\n",
    "# Plot the probability map\n",
    "def plot_voxel_grid(voxel_grid, probability_map, voxel_size, map_bounds):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    filled = np.argwhere(probability_map > 0)\n",
    "    colors = plt.cm.get_cmap('RdYlGn')(probability_map[filled[:, 0], filled[:, 1], filled[:, 2]])\n",
    "    \n",
    "    for (ix, iy, iz), color in zip(filled, colors):\n",
    "        x = ix * voxel_size + map_bounds[0]\n",
    "        y = iy * voxel_size + map_bounds[2]\n",
    "        z = iz * voxel_size + map_bounds[4]\n",
    "        voxel = [\n",
    "            [x, y, z],\n",
    "            [x + voxel_size, y, z],\n",
    "            [x + voxel_size, y + voxel_size, z],\n",
    "            [x, y + voxel_size, z],\n",
    "            [x, y, z + voxel_size],\n",
    "            [x + voxel_size, y, z + voxel_size],\n",
    "            [x + voxel_size, y + voxel_size, z + voxel_size],\n",
    "            [x, y + voxel_size, z + voxel_size]\n",
    "        ]\n",
    "        ax.add_collection3d(Poly3DCollection([voxel], facecolors=color, edgecolor='k', linewidths=0.1, alpha=0.75))\n",
    "    \n",
    "    ax.set_xlim(map_bounds[0], map_bounds[1])\n",
    "    ax.set_ylim(map_bounds[2], map_bounds[3])\n",
    "    ax.set_zlim(map_bounds[4], map_bounds[5])\n",
    "    plt.show()\n",
    "\n",
    "# Plot the probability map using open3d\n",
    "def plot_voxel_grid_open3d(normalized_scores, voxel_grid, voxel_size, map_bounds):\n",
    "    points = []\n",
    "    colors = []\n",
    "    cmap = plt.cm.get_cmap('RdYlGn')\n",
    "\n",
    "    filled = np.argwhere(normalized_scores > 0)\n",
    "    \n",
    "    for (ix, iy, iz) in filled:\n",
    "        x = ix * voxel_size + map_bounds[0]\n",
    "        y = iy * voxel_size + map_bounds[2]\n",
    "        z = iz * voxel_size + map_bounds[4]\n",
    "        if voxel_grid.voxel_counts[ix, iy, iz] < 1:\n",
    "            color = [1, 1, 1]  # White for voxels with almost no points\n",
    "        else:\n",
    "            color = cmap(normalized_scores[ix, iy, iz])[:3]  # Get RGB color from colormap\n",
    "        points.append([x, y, z])\n",
    "        colors.append(color)\n",
    "\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(point_cloud, voxel_size)\n",
    "    \n",
    "    o3d.visualization.draw_geometries([voxel_grid])\n",
    "\n",
    "    # Create colorbar\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    cb1 = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), cax=ax, orientation='horizontal')\n",
    "    cb1.set_label('Static Score')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "## NOTE: VoxelGrid can work with local ego coordinates otherwise too big, better to use voxelhashmap\n",
    "# # Define parameters\n",
    "# voxel_size = 10  # Adjust based on your requirements\n",
    "# map_bounds = [-250, 250, -250, 250, -10, 10]  # Example bounds, adjust as needed\n",
    "\n",
    "# # Initialize voxel grid\n",
    "# voxel_grid = VoxelGrid(voxel_size, map_bounds)\n",
    "\n",
    "# # Process each radar scan\n",
    "# for frame_id, point_cloud in radar_scans.items():\n",
    "#     voxel_grid.update_with_scan(point_cloud)\n",
    "\n",
    "# # Retrieve the final probabilities\n",
    "# probability_map = voxel_grid.get_normalized_scores()\n",
    "\n",
    "# plot_voxel_grid_open3d(probability_map, voxel_grid, voxel_size, map_bounds)\n",
    "# # plot_voxel_grid(voxel_grid, probability_map, voxel_size, map_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "class VoxelHashMap:\n",
    "    def __init__(self, voxel_size):\n",
    "        self.voxel_size = voxel_size\n",
    "        self.voxel_map = defaultdict(int)  # Using a default dictionary to store voxel counts\n",
    "\n",
    "    def point_to_voxel_key(self, point):\n",
    "        ix = int(np.floor(point[0] / self.voxel_size))\n",
    "        iy = int(np.floor(point[1] / self.voxel_size))\n",
    "        iz = int(np.floor(point[2] / self.voxel_size))\n",
    "        return (ix, iy, iz)\n",
    "    \n",
    "    def update_with_scan(self, point_cloud):\n",
    "        for point in point_cloud:\n",
    "            voxel_key = self.point_to_voxel_key(point)\n",
    "            self.voxel_map[voxel_key] += 1\n",
    "    \n",
    "    def get_normalized_scores(self):\n",
    "        max_count = max(self.voxel_map.values()) if self.voxel_map else 1\n",
    "        normalized_scores = {k: 1- (v / max_count) for k, v in self.voxel_map.items()}\n",
    "        return normalized_scores\n",
    "\n",
    "    def query_point_score(self, point):\n",
    "        voxel_key = self.point_to_voxel_key(point)\n",
    "        return self.voxel_map.get(voxel_key, 0) / max(self.voxel_map.values(), default=1)\n",
    "\n",
    "    def assign_scores_to_pointcloud(self, point_cloud):\n",
    "        scores = []\n",
    "        for point in point_cloud:\n",
    "            score = self.query_point_score(point)\n",
    "            scores.append(1 - score) # Undo the 1-normalizd score for consisten visualization\n",
    "        return np.hstack((point_cloud, np.array(scores).reshape(-1, 1)))\n",
    "\n",
    "\n",
    "# Plot the probability map using open3d\n",
    "def plot_voxel_hash_map_open3d(normalized_scores, voxel_hash_map, voxel_size):\n",
    "    points = []\n",
    "    colors = []\n",
    "    cmap = plt.cm.get_cmap('RdYlGn')\n",
    "\n",
    "    for (ix, iy, iz), score in normalized_scores.items():\n",
    "        x = (ix + 0.5) * voxel_size  # Center of the voxel\n",
    "        y = (iy + 0.5) * voxel_size\n",
    "        z = (iz + 0.5) * voxel_size\n",
    "        if voxel_hash_map.voxel_map[(ix, iy, iz)] < 1:\n",
    "            color = [1, 1, 1]  # White for voxels with no points\n",
    "        else:\n",
    "            color = cmap(score)[:3]  # Get RGB color from colormap\n",
    "        points.append([x, y, z])\n",
    "        colors.append(color)\n",
    "\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud_within_bounds(point_cloud, voxel_size, point_cloud.get_min_bound(), point_cloud.get_max_bound())\n",
    "    \n",
    "    o3d.visualization.draw_geometries([voxel_grid])\n",
    "\n",
    "    # Create colorbar\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    cb1 = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), cax=ax, orientation='horizontal')\n",
    "    cb1.set_label('Static Score')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create Dataloader for each scene in a record\n",
    "voxel_prior_dataloaders = {ref_scene_name : NuScenesMultipleRadarMultiSweeps(\n",
    "    data_dir=data_dir,\n",
    "    nusc=nuscenes_exp[ref_split],\n",
    "    sequence=int(ref_scene_name.split(\"-\")[-1]),\n",
    "    sensors=sensors,\n",
    "    nsweeps=num_sweeps,\n",
    "    ref_frame='global',\n",
    "    ref_sensor=ref_sensor,\n",
    "    apply_dpr=True,\n",
    "    filter_points=False,\n",
    "    ransac_threshold=dpr_thresh\n",
    "\n",
    ")}\n",
    "\n",
    "for matched_scene, data in closest_scenes.items():\n",
    "    voxel_prior_dataloaders[matched_scene] = NuScenesMultipleRadarMultiSweeps(\n",
    "    data_dir=data_dir,\n",
    "    nusc=nuscenes_exp[data['split']],\n",
    "    sequence=int(matched_scene.split(\"-\")[-1]),\n",
    "    sensors=sensors,\n",
    "    nsweeps=num_sweeps,\n",
    "    ref_frame='global',\n",
    "    ref_sensor=ref_sensor,\n",
    "    apply_dpr=True,\n",
    "    filter_points=False,\n",
    "    ransac_threshold=dpr_thresh\n",
    ")\n",
    "\n",
    "\n",
    "scene_scans = {name: {i:dataloader[i][0][:,:3] for i in range(len(dataloader))} for name,dataloader in voxel_prior_dataloaders.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 1 # Size of region in the map we want to track in meters\n",
    "def create_voxel_map(radar_scans):\n",
    "    # Initialize voxel hash map\n",
    "    voxel_hash_map = VoxelHashMap(voxel_size)\n",
    "\n",
    "    # Process each radar scan\n",
    "    for frame_id, point_cloud in radar_scans.items():\n",
    "        voxel_hash_map.update_with_scan(point_cloud)\n",
    "    return voxel_hash_map\n",
    "\n",
    "def plot_voxel_map(voxel_hash_map):\n",
    "    # Retrieve the normalized scores\n",
    "    normalized_scores = voxel_hash_map.get_normalized_scores()\n",
    "\n",
    "    plot_voxel_hash_map_open3d(normalized_scores, voxel_hash_map, voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_voxel_maps = {name : create_voxel_map(scans) for name,scans in scene_scans.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_voxel_map(scene_voxel_maps[ref_scene_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelled_scan =  voxel_hash_map.assign_scores_to_pointcloud(dataloader[10][0][: ,:3])\n",
    "# labelled_map =  voxel_hash_map.assign_scores_to_pointcloud(scene_maps['scene-0172'][: ,:3])\n",
    "# sps_labeler.plot_labeled_map_bev(labelled_scan, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Octomaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_octomap(dl, resolution=0.1):\n",
    "    # Initialize the OctoMap with the specified resolution\n",
    "    poses = dl.global_poses\n",
    "    num_readings = dl.num_readings\n",
    "    octree = octomap.OcTree(resolution)\n",
    "    \n",
    "    # Define occupancy thresholds\n",
    "    # prob_hit = 0.7  # Probability that a voxel is occupied when a point is observed\n",
    "    # prob_miss = 0.4  # Probability that a voxel is free when a ray passes through\n",
    "    # clamping_thres_min = 0.12  # Minimum probability value for occupancy\n",
    "    # clamping_thres_max = 0.97  # Maximum probability value for occupancy\n",
    "\n",
    "    # octree.setProbHit(prob_hit)\n",
    "    # octree.setProbMiss(prob_miss)\n",
    "    # octree.setClampingThresMin(clamping_thres_min)\n",
    "    # octree.setClampingThresMax(clamping_thres_max)\n",
    "\n",
    "    for i in tqdm(range(num_readings)):\n",
    "        pointcloud = dl[i][0]\n",
    "        pose = poses[i]\n",
    "        sensor_origin = pose[:3, 3]\n",
    "        octree.insertPointCloud(pointcloud, sensor_origin)\n",
    "\n",
    "    # occupied, empty = octree.extractPointCloud()\n",
    "    return octree\n",
    "\n",
    "\n",
    "\n",
    "# def build_octomap(map, resolution=0.1):\n",
    "#     tree = octomap.OcTree(resolution)\n",
    "#     for point in map:\n",
    "#         x,y,z = point[:3]\n",
    "#         tree.updateNode((x,y,z), True)\n",
    "#     tree.updateInnerOccupancy()\n",
    "#     occupied, free = tree.extractPointCloud()\n",
    "\n",
    "#     return tree, occupied\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occupancy_score_dist(omap):\n",
    "    occupancy_dist = []\n",
    "    for node in omap.begin_leafs():\n",
    "        x,y,z = node.getCoordinate()\n",
    "        occupancy = node.getOccupancy()\n",
    "        occupancy_dist.append(occupancy)\n",
    "        # print(f\"Node at ({x:0.2f}, {y:0.2f}, {z:0.2f}) has occupancy probability {occupancy:0.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(occupancy_dist, bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of Occupancy Values')\n",
    "    plt.xlabel('Occupancy Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_high_occupancy_points(octree, threshold):\n",
    "    \"\"\"\n",
    "    Extract points from the OctoMap with occupancy greater than the specified threshold.\n",
    "\n",
    "    Args:\n",
    "        octomap_file (str): Path to the OctoMap file.\n",
    "        threshold (float): The occupancy probability threshold.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The extracted point cloud as an array of shape (N, 3).\n",
    "    \"\"\"\n",
    "    # List to store the filtered points\n",
    "    points = []\n",
    "\n",
    "    # Iterate over all leaf nodes in the OctoMap\n",
    "    for node in octree.begin_leafs():\n",
    "        occupancy = node.getOccupancy()\n",
    "        if occupancy > threshold:\n",
    "            x, y, z = node.getCoordinate()\n",
    "            points.append([x, y, z])\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    pointcloud = np.array(points)\n",
    "    return pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_octomaps = {name: build_octomap(dl) for name,dl in dataloaders.items()}\n",
    "# scene_octomaps = {name: build_octomap(map) for name,map in scene_maps.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_occupancy_score_dist(scene_octomaps[ref_scene_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCCUPANCY_THRESHOLD = 0.5\n",
    "scene_maps_high_occ = {name: extract_high_occupancy_points(omap, OCCUPANCY_THRESHOLD) for name,omap in scene_octomaps.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maps(scene_maps_high_occ, scene_poses, zoom_level=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test if occlusion check works\n",
    "sample_omap = scene_octomaps[ref_scene_name]\n",
    "sample_scan = dataloaders[ref_scene_name][10][0]\n",
    "sample_point = sample_scan[0]\n",
    "\n",
    "node = sample_omap.search(sample_point)\n",
    "if node is not None:\n",
    "    occupied = sample_omap.isNodeOccupied(node)\n",
    "    print(occupied)\n",
    "else:\n",
    "    print(\"Point not found in Octomap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, omap in scene_octomaps.items():\n",
    "    print(name, ref_scene_name)\n",
    "    map_ = scene_maps[name]\n",
    "    occupancy_dist = []\n",
    "    misses = 0\n",
    "    for p in tqdm(desc=f'Processing Scene: {name}', iterable=map_[:,:3]):\n",
    "        try: \n",
    "            occupancy_dist.append(omap.isNodeOccupied(omap.search(p)))\n",
    "        except octomap.NullPointerException:\n",
    "            misses+=1\n",
    "    print(f\"{misses} points could not be found in the map\")\n",
    "    # occupancy_dist = [omap.isNodeOccupied(omap.search(p[:3])) for p in map_]\n",
    "    ## Free, Occupied, Total\n",
    "    print(f\"Occupancy Dist for Map: {name} | Total: {len(occupancy_dist)} Occupied:{sum(map(int, occupancy_dist))} Free: {len(occupancy_dist) - sum(map(int, occupancy_dist))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable, get_cmap\n",
    "# Retrieve all occupied nodes and their occupancy scores\n",
    "occupied_nodes = []\n",
    "empty_nodes = []\n",
    "occupancy_scores = []\n",
    "octree = scene_octomaps[ref_scene_name]\n",
    "\n",
    "# Iterate through all leaf nodes in the octree\n",
    "for node in octree.begin_leafs():\n",
    "    occupancy = node.getOccupancy()\n",
    "    x, y, z = node.getCoordinate()\n",
    "    if occupancy > 0.5:\n",
    "        occupied_nodes.append([x, y, z])\n",
    "        occupancy_scores.append(occupancy)\n",
    "    else:\n",
    "        empty_nodes.append([x, y, z])\n",
    "        \n",
    "\n",
    "# Convert to numpy array for easier handling\n",
    "occupied_nodes = np.array(occupied_nodes)\n",
    "empty_nodes = np.array(empty_nodes)\n",
    "occupancy_scores = np.array(occupancy_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize occupancy scores for colormap\n",
    "norm = Normalize(vmin=occupancy_scores.min(), vmax=occupancy_scores.max())\n",
    "cmap = get_cmap('RdYlGn')  # Red-Yellow-Green colormap\n",
    "colors = cmap(norm(occupancy_scores))\n",
    "\n",
    "# Create Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(occupied_nodes)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])  # Open3D uses RGB colors\n",
    "resolution = 0.5\n",
    "\n",
    "empty_pcd = o3d.geometry.PointCloud()\n",
    "empty_pcd.points = o3d.utility.Vector3dVector(empty_nodes)\n",
    "\n",
    "# Create voxel grids for occupied and empty spaces\n",
    "occupied_voxels = o3d.geometry.VoxelGrid.create_from_point_cloud(\n",
    "  pcd, voxel_size=resolution\n",
    ")\n",
    "empty_voxels = o3d.geometry.VoxelGrid.create_from_point_cloud(\n",
    "  empty_pcd, voxel_size=resolution\n",
    ")\n",
    "\n",
    "# Set colors for the voxel grids\n",
    "# occupied_voxels.paint_uniform_color([1.0, 0, 0])\n",
    "# empty_voxels.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "\n",
    "# Create a visualizer\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "# Add geometries to the visualizer\n",
    "# vis.add_geometry(pcd)\n",
    "vis.add_geometry(occupied_voxels)\n",
    "vis.add_geometry(empty_voxels)\n",
    "\n",
    "# Run the visualizer\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable-Point Labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCCLUDED_POINT = -1  # Define a constant for occluded points\n",
    "\n",
    "class AutoLabeler:\n",
    "    def __init__(self,\n",
    "                 scene_maps, \n",
    "                 ref_map_id, \n",
    "                 scene_octomaps, \n",
    "                 lidar_labels=None, \n",
    "                 dynamic_priors=None, \n",
    "                 use_octomaps=True, \n",
    "                 search_in_radius=False,\n",
    "                 downsample=False, \n",
    "                 voxel_size=0.5):\n",
    "        self.use_octomaps = use_octomaps\n",
    "        self.maps = scene_maps\n",
    "        self.octomaps = scene_octomaps\n",
    "        self.lidar_labels = lidar_labels\n",
    "        self.dynamic_priors = dynamic_priors\n",
    "        self.search_in_radius = search_in_radius\n",
    "\n",
    "        if downsample:\n",
    "            self.maps = {}\n",
    "            for name,map in scene_maps.items():\n",
    "                # Create an Open3D point cloud object\n",
    "                point_cloud = o3d.geometry.PointCloud()\n",
    "                point_cloud.points = o3d.utility.Vector3dVector(map[:, :3])\n",
    "                ## TODO: Try adding dyn_prop and compare those points, if dyn_prop does not match then return np.inf\n",
    "                # rcs_as_normals = np.zeros((map.shape[0], 3))\n",
    "                # rcs_as_normals[:,0] = map[:,3]\n",
    "                # rcs_as_normals[:,1] = map[:,-1] # compensated velocities\n",
    "                \n",
    "                # point_cloud.normals = o3d.utility.Vector3dVector(rcs_as_normals) # RCS \n",
    "                # Downsample the point cloud\n",
    "                ref_map_sampled = point_cloud.voxel_down_sample(voxel_size=voxel_size)\n",
    "                # ref_map_sampled_rcs = np.asarray(ref_map_sampled.normals)[:,0].reshape(-1, 1)\n",
    "                # ref_map_sampled_cv = np.asarray(ref_map_sampled.normals)[:,1].reshape(-1, 1)\n",
    "                # ref_map_sampled = np.asarray(ref_map_sampled.points)\n",
    "                map_points = np.asarray(ref_map_sampled.points)\n",
    "\n",
    "                # map_points = np.hstack([ref_map_sampled, ref_map_sampled_rcs, ref_map_sampled_cv])\n",
    "                # map_points = map_points[map_points[:, -1] <= 0.25]\n",
    "                self.maps[name] = map_points\n",
    "\n",
    "        self.ref_map_id = ref_map_id\n",
    "        self.maps_ids = list(self.maps.keys())\n",
    "        self.labelled_maps = {}\n",
    "\n",
    "        if self.lidar_labels is not None:\n",
    "            self.lidar_labeled_scene_maps = {}\n",
    "            for name in self.maps:\n",
    "                labels = self.lidar_labels[name]\n",
    "                radar_map = self.maps[name]\n",
    "                new_map = transfer_labels(labels, radar_map[:, :3])\n",
    "                self.lidar_labeled_scene_maps[name] = new_map\n",
    "\n",
    "\n",
    "    def label_maps(self):\n",
    "        for map_id, ref_map in self.maps.items():\n",
    "            max_features = []\n",
    "            print(f\"Extracting features for {map_id}...\")\n",
    "\n",
    "            for point in tqdm(ref_map):\n",
    "                dis = []\n",
    "                for query_map in self.maps_ids:\n",
    "                    if query_map == map_id or len(self.maps[query_map]) < 1:\n",
    "                        continue\n",
    "                    occluded = self.is_point_occluded(point, query_map) if self.use_octomaps else False\n",
    "                    if not occluded:\n",
    "                        if self.search_in_radius:\n",
    "                            d_radius = self.get_points_within_radius(point, self.maps[query_map])\n",
    "                            dis.extend(d_radius)\n",
    "                        else:\n",
    "                            d = self.get_distance_to_closest_point(point, self.maps[query_map])\n",
    "                            dis.append(d)\n",
    "\n",
    "\n",
    "                        # if d < 0.05: # If its close enough\n",
    "                        #     dis.append(d)\n",
    "                        # else:\n",
    "                        #     # not a good correspondence\n",
    "                        #     dis.append(OCCLUDED_POINT)\n",
    "                    else:\n",
    "                        dis.append(OCCLUDED_POINT)\n",
    "                \n",
    "                if len(dis):\n",
    "                    max_dis = max(dis)\n",
    "                else:\n",
    "                    max_dis = np.inf\n",
    "\n",
    "                if max_dis != OCCLUDED_POINT:\n",
    "                    max_dis = 1 - np.exp(-max_dis * (max_dis / 100))\n",
    "            \n",
    "\n",
    "                max_features.append(max_dis)\n",
    "\n",
    "            labeled_map = np.hstack((ref_map, np.array(max_features).reshape(-1, 1)))\n",
    "            labeled_map[:, -1] = 1 - labeled_map[:, -1] # Using 1 for stability\n",
    "            # labeled_map[:, -1] = labeled_map[:, -1] # Using 1 for instability\n",
    "            # labeled_map = labeled_map[labeled_map[:, -1] <= 1.0]\n",
    "\n",
    "            if self.lidar_labels is not None:\n",
    "                labeled_map[:, -1] = labeled_map[:, -1] * self.lidar_labeled_scene_maps[map_id][:, -1] # combine lidar proxy labels\n",
    "            \n",
    "            if self.dynamic_priors:\n",
    "                voxel_hash_map = self.dynamic_priors[map_id]\n",
    "                scan_dynamic_scores = voxel_hash_map.assign_scores_to_pointcloud(labeled_map[:, :3])\n",
    "                labeled_map[:, -1] *= scan_dynamic_scores[:,-1]\n",
    "\n",
    "            labeled_map[:, -1] = np.clip(0,1, labeled_map[:, -1])\n",
    "            self.labelled_maps[map_id] = labeled_map\n",
    "        self.labeled_environment_map = np.vstack([m for m in self.labelled_maps.values()])\n",
    "\n",
    "\n",
    "    def get_distance_to_closest_point(self, point, points, euclidean_weight=1, rcs_weight=0):\n",
    "        # Extract the RCS value of the point\n",
    "        if rcs_weight > 0:\n",
    "            point_rcs = point[3]  # Assuming the 4th column (index 3) is RCS\n",
    "            # Calculate the differences in RCS values\n",
    "            rcs_differences = np.abs(points[:, 3] - point_rcs)\n",
    "        else:\n",
    "            rcs_differences = 0\n",
    "\n",
    "        # Calculate Euclidean distances\n",
    "        euclidean_distances = np.linalg.norm(points[:, :3] - point[:3], axis=1)\n",
    "\n",
    "        # Combine Euclidean distance and RCS difference to form a composite distance\n",
    "        # Here we use adjustable weights for both distance and RCS difference\n",
    "        combined_distances = np.sqrt((euclidean_weight * euclidean_distances)**2 + (rcs_weight * rcs_differences)**2)\n",
    "        return np.min(combined_distances)\n",
    "    \n",
    "\n",
    "    def get_points_within_radius(self, point, points, radius=1, euclidean_weight=1, rcs_weight=0):\n",
    "        \"\"\"\n",
    "        Get all points within a specified radius from the given point.\n",
    "\n",
    "        Parameters:\n",
    "        - point: The reference point.\n",
    "        - points: An array of points to check against.\n",
    "        - radius: The radius within which to find points (default is 0.5 meters).\n",
    "        - euclidean_weight: The weight for the Euclidean distance.\n",
    "        - rcs_weight: The weight for the RCS difference.\n",
    "\n",
    "        Returns:\n",
    "        - A list of points within the specified radius.\n",
    "        \"\"\"\n",
    "        # Extract the RCS value of the point\n",
    "        if rcs_weight > 0:\n",
    "            point_rcs = point[3]  # Assuming the 4th column (index 3) is RCS\n",
    "            # Calculate the differences in RCS values\n",
    "            rcs_differences = np.abs(points[:, 3] - point_rcs)\n",
    "        else:\n",
    "            rcs_differences = np.zeros(len(points))  # Ensure the array shape matches\n",
    "\n",
    "        # Calculate Euclidean distances\n",
    "        euclidean_distances = np.linalg.norm(points[:, :3] - point[:3], axis=1)\n",
    "\n",
    "        # Combine Euclidean distance and RCS difference to form a composite distance\n",
    "        combined_distances = np.sqrt((euclidean_weight * euclidean_distances)**2 + (rcs_weight * rcs_differences)**2)\n",
    "\n",
    "        # Find indices of points within the specified radius\n",
    "        within_radius_indices = np.where(combined_distances <= radius)[0]\n",
    "\n",
    "        # Get the points within the specified radius\n",
    "        points_within_radius = points[within_radius_indices]\n",
    "\n",
    "        return combined_distances[within_radius_indices].tolist()\n",
    "\n",
    "\n",
    "    def is_point_occluded(self, point, map_id):\n",
    "        # Placeholder function to check if a point is occluded using octomap\n",
    "        # Replace with actual occlusion check logic\n",
    "        if self.use_octomaps and map_id in self.octomaps:\n",
    "            octree = self.octomaps[map_id]\n",
    "            node = octree.search(point)\n",
    "            try:\n",
    "                if node and octree.isNodeOccupied(node):\n",
    "                    return True\n",
    "            except octomap.NullPointerException:\n",
    "                return False # NOTE: If a search fails, then return occluded\n",
    "        return False\n",
    "\n",
    "    def label_scan(self, scan, map_id=None):\n",
    "        if map_id is None:\n",
    "            # Use the combined \"environment\" map\n",
    "            print(f\"Registering scan to combined environment map...\")\n",
    "            target_map = self.labeled_environment_map\n",
    "        else:\n",
    "            print(f\"Registering scan to {map_id} map...\")\n",
    "            target_map = self.labelled_maps[map_id]\n",
    "\n",
    "        # Register scan to labeled map\n",
    "        transformation = self.icp_registration(scan[:, :3], target_map[:, :3])\n",
    "        scan[:, :3] = self.apply_transformation(scan[:, :3], transformation)\n",
    "\n",
    "        # Transfer labels from labeled map to scan\n",
    "        scan_labels = []\n",
    "        labeled_map_points = target_map[:, :3]\n",
    "        labeled_map_labels = target_map[:, -1]\n",
    "\n",
    "        \n",
    "            \n",
    "        for point in tqdm(scan[:, :3]):\n",
    "            distances = np.linalg.norm(labeled_map_points - point, axis=1)\n",
    "            closest_point_idx = np.argmin(distances)\n",
    "            scan_labels.append(labeled_map_labels[closest_point_idx])\n",
    "\n",
    "        scan_labels = np.array(scan_labels)\n",
    "\n",
    "        labeled_scan = np.hstack((scan, scan_labels.reshape(-1, 1)))\n",
    "        return labeled_scan\n",
    "        \n",
    "\n",
    "    def icp_registration(self, source_points, target_points):\n",
    "        source = o3d.geometry.PointCloud()\n",
    "        target = o3d.geometry.PointCloud()\n",
    "        source.points = o3d.utility.Vector3dVector(source_points)\n",
    "        target.points = o3d.utility.Vector3dVector(target_points)\n",
    "\n",
    "        threshold = 0.02  # Distance threshold for ICP\n",
    "        trans_init = np.identity(4)\n",
    "        reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, threshold, trans_init,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "        return reg_p2p.transformation\n",
    "\n",
    "    def apply_transformation(self, points, transformation):\n",
    "        points_hom = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "        transformed_points_hom = points_hom.dot(transformation.T)\n",
    "        return transformed_points_hom[:, :3]\n",
    "\n",
    "    def plot_bev(self, points, labels, title=\"Bird's Eye View\",size=1):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.scatter(points[:, 0], points[:, 1], c=labels, cmap='RdYlGn', s=size)\n",
    "        plt.colorbar(label='Stability')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_labeled_map_bev(self, labeled_map, size=1):\n",
    "        points = labeled_map[:, :3]\n",
    "        labels = labeled_map[:, -1]\n",
    "        self.plot_bev(points, labels, title=f\"BEV of Labeled Map\", size=size)\n",
    "\n",
    "    def plot_labeled_scan_bev(self, labeled_scan, size=1):\n",
    "        points = labeled_scan[:, :3]\n",
    "        labels = labeled_scan[:, -1]\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.scatter(points[:, 0], points[:, 1], c=labels, cmap='RdYlGn', s=size)\n",
    "        \n",
    "        # self.labels[map_id] = np.load(os.path.join(self.main_dir, 'labelled', f\"{map_id}_labeled.npy\"))\n",
    "        # map_points = self.labels[map_id][:, :3]\n",
    "        # map_labels = self.labels[map_id][:, 3]\n",
    "        # plt.scatter(map_points[:, 0], map_points[:, 1], c=map_labels, cmap='Accent', s=5)\n",
    "        \n",
    "        plt.colorbar(label='Stability')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title(\"Labeled scan and map\")\n",
    "\n",
    "\n",
    "    def load_octomap(self, filepath):\n",
    "        # Placeholder function to load octomap\n",
    "        # Replace with actual implementation\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return octomap.OcTree(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_octomap(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return octomap.OcTree(f.read())\n",
    "    \n",
    "def save_octomap(path, tree):\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(tree.writeBinary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_labeler = AutoLabeler(\n",
    "    scene_maps=cropped_scene_maps, ref_map_id=ref_scene_name,\n",
    "    scene_octomaps=scene_octomaps, lidar_labels=None, \n",
    "    dynamic_priors=scene_voxel_maps,  use_octomaps=True, search_in_radius=True,\n",
    "    downsample=True, voxel_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_labeler.label_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_labeler.plot_labeled_map_bev(sps_labeler.labelled_maps[ref_scene_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dist = sps_labeler.labelled_maps[ref_scene_name][:,-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(labels_dist, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Assigned Labels for a Scene')\n",
    "plt.xlabel('Stability Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_scan = dataloaders[ref_scene_name][10][0]\n",
    "sample_scan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_scan = sps_labeler.label_scan(sample_scan, map_id=ref_scene_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dist = labelled_scan[:,-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(labels_dist, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Assigned Labels for a Scan')\n",
    "plt.xlabel('Stability Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_labeler.plot_labeled_scan_bev(labelled_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = \"labelled_maps/dynamic_prior_5sweep_radius_corr/\"\n",
    "from pathlib import Path\n",
    "Path(labels_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for map_name, lmap in sps_labeler.labelled_maps.items():\n",
    "    points = lmap[:, :3]\n",
    "    stable_probs = lmap[:,-1]\n",
    "    filename = f\"{labels_dir}/{map_name}.asc\"\n",
    "    np.savetxt(filename,\n",
    "               np.hstack([points,stable_probs.reshape(-1,1)]),\n",
    "               fmt='%.6f', delimiter=' ',\n",
    "               header='x y z stable_prob',\n",
    "               comments='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{name: dl.scene['first_sample_token'] for name,dl in dataloaders.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_split, data['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar_slam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
